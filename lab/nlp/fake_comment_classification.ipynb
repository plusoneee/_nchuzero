{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "虛假評論分類.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QbKzcsE1d5Mq"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "093d2397112f445a8d2b82b482f84135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a2a6f2d4752d4a59a0bb197b9823ba5d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f7ff4983dc5e49b3ba3d2a895bfff2d8",
              "IPY_MODEL_c0c5c91b332c4a949984508f5a9f6846"
            ]
          }
        },
        "a2a6f2d4752d4a59a0bb197b9823ba5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7ff4983dc5e49b3ba3d2a895bfff2d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_75dbd74d18df4a578376e41dcb0807f3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 109540,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 109540,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_719ce46fb09946d89e7d16d5c7a5b49b"
          }
        },
        "c0c5c91b332c4a949984508f5a9f6846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_334f7b64c0aa496aabe86585be111b4b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 110k/110k [00:00&lt;00:00, 1.76MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46bf5dd493b64caaa07cc2bb5719f376"
          }
        },
        "75dbd74d18df4a578376e41dcb0807f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "719ce46fb09946d89e7d16d5c7a5b49b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "334f7b64c0aa496aabe86585be111b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46bf5dd493b64caaa07cc2bb5719f376": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5bd7398144f4c438badd4107c5b31bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_51189c61eb3f409e8c44a2999ca0a3d5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a19a3777d22a47499f969140bbf5cc81",
              "IPY_MODEL_1675a331a4bf4dcdb01b13b0eb16061d"
            ]
          }
        },
        "51189c61eb3f409e8c44a2999ca0a3d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a19a3777d22a47499f969140bbf5cc81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0d261218e0f145d6815d8f083f0ee85f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 624,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 624,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f1581dc14f74c3dac91a927be256d07"
          }
        },
        "1675a331a4bf4dcdb01b13b0eb16061d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6607cd0aba58499cad804710f14e73df",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 624/624 [00:27&lt;00:00, 22.4B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f23230f23f14135b5ec9bfc42d8b89f"
          }
        },
        "0d261218e0f145d6815d8f083f0ee85f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f1581dc14f74c3dac91a927be256d07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6607cd0aba58499cad804710f14e73df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f23230f23f14135b5ec9bfc42d8b89f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4c9dc13925324d6c92fe4e544de90aa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9d6db7be0b35438288bbeecef3273d72",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_51ffb8ad2d9c4d4a858a6a91aa1a028d",
              "IPY_MODEL_c7c4c47e20704faebf46a6e8f178de0d"
            ]
          }
        },
        "9d6db7be0b35438288bbeecef3273d72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51ffb8ad2d9c4d4a858a6a91aa1a028d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8a8807e6a92d4990879024c89281f5e8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 411577189,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 411577189,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_437f70eff79b4e0b8c8ee17c4d78d721"
          }
        },
        "c7c4c47e20704faebf46a6e8f178de0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_70c9941a45524b118567dc114877c5e2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 412M/412M [00:06&lt;00:00, 67.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_104e911b4013474daae96dc54c476eb7"
          }
        },
        "8a8807e6a92d4990879024c89281f5e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "437f70eff79b4e0b8c8ee17c4d78d721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70c9941a45524b118567dc114877c5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "104e911b4013474daae96dc54c476eb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbKzcsE1d5Mq"
      },
      "source": [
        "## Flow in this tutorial.\n",
        "1. Import Lib\n",
        "2. Load Dataset. `(train.json & test.json)`\n",
        "3. Data Pre-processing.\n",
        "4. BERT Embeddin.\n",
        "5. Build SVM classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxG82CoFpRRt"
      },
      "source": [
        "## 1. Import Library\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLZD8S-Mnrt3"
      },
      "source": [
        "from google.colab import files\n",
        "import json\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas.core.frame import DataFrame\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPSfKrvbq-7-"
      },
      "source": [
        "You will have to install `transformers` library each time you reconnect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfu-rA3qomuq",
        "outputId": "b9dd7580-a57a-4b33-e49c-1bd472c8b4b9"
      },
      "source": [
        "!pip install transformers \n",
        "from transformers import BertTokenizer, BertModel,BertConfig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/b1/41130a228dd656a1a31ba281598a968320283f48d42782845f6ba567f00b/transformers-4.2.2-py3-none-any.whl (1.8MB)\n",
            "\r\u001b[K     |▏                               | 10kB 25.9MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 33.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 37.4MB/s eta 0:00:01\r\u001b[K     |▊                               | 40kB 35.9MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 33.7MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61kB 35.9MB/s eta 0:00:01\r\u001b[K     |█▎                              | 71kB 20.5MB/s eta 0:00:01\r\u001b[K     |█▌                              | 81kB 17.5MB/s eta 0:00:01\r\u001b[K     |█▊                              | 92kB 18.7MB/s eta 0:00:01\r\u001b[K     |█▉                              | 102kB 19.8MB/s eta 0:00:01\r\u001b[K     |██                              | 112kB 19.8MB/s eta 0:00:01\r\u001b[K     |██▎                             | 122kB 19.8MB/s eta 0:00:01\r\u001b[K     |██▍                             | 133kB 19.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 143kB 19.8MB/s eta 0:00:01\r\u001b[K     |██▉                             | 153kB 19.8MB/s eta 0:00:01\r\u001b[K     |███                             | 163kB 19.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 174kB 19.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 184kB 19.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 194kB 19.8MB/s eta 0:00:01\r\u001b[K     |███▊                            | 204kB 19.8MB/s eta 0:00:01\r\u001b[K     |████                            | 215kB 19.8MB/s eta 0:00:01\r\u001b[K     |████                            | 225kB 19.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 235kB 19.8MB/s eta 0:00:01\r\u001b[K     |████▌                           | 245kB 19.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 256kB 19.8MB/s eta 0:00:01\r\u001b[K     |████▉                           | 266kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 276kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 286kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 296kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 307kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 317kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 327kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 337kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 348kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 358kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 368kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 378kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 389kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 399kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 409kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 419kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 430kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 440kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 450kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 460kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 471kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 481kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 491kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 501kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 512kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 522kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 532kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 542kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 552kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 563kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 573kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 583kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 593kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 604kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 614kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 624kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 634kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 645kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 655kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 665kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 675kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 686kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 696kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 706kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 716kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 727kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 737kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 747kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 757kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 768kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 778kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 788kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 798kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 808kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 819kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 829kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 839kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 849kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 860kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 870kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 880kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 890kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 901kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 911kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 921kB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 931kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 942kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 952kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 962kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 972kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 983kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 993kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.0MB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.0MB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.0MB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.0MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.0MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.1MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.1MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.1MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.1MB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1MB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.1MB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.1MB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.1MB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.1MB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2MB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.2MB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.2MB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.2MB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.2MB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.2MB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2MB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.2MB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.2MB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.2MB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.3MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.3MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.3MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.3MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.3MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.3MB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.3MB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.3MB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.3MB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.4MB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.4MB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.4MB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.4MB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.4MB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.4MB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.4MB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.4MB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.4MB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.4MB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.5MB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.5MB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.5MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.5MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.5MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.5MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.5MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.5MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.5MB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.5MB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.6MB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.6MB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.6MB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.6MB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.6MB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.6MB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.6MB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.6MB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.6MB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.6MB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.7MB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.7MB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.7MB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.7MB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.7MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.7MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.7MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.7MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.7MB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.8MB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.8MB 19.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.8MB 19.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 58.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 49.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=e020b9532d7749be16f5158ef32db727eb61cfe6f188dfbbd32ac3c150579299\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHd8HLmYp-x4"
      },
      "source": [
        "##2. Load Dataset\n",
        "1. Create `upload_file_to_colab()` function for upload files `(train.json & test.json)` to `colab`.\n",
        "2. Call function and upload files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp2D44KLoeqP"
      },
      "source": [
        "# Step 1.\n",
        "def upload_file_to_colab():\n",
        "  uploaded = files.upload()\n",
        "  for fileName in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes.'.format(name=fileName, length=len(uploaded[fileName])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "B24EkBMgpooi",
        "outputId": "5fd22605-ee70-497d-e580-9106070ab043"
      },
      "source": [
        "# Step 2.\n",
        "# upload train.json\n",
        "print('Upload train.json please.\\n')\n",
        "upload_file_to_colab()\n",
        "\n",
        "# upload test.json\n",
        "print('Upload test.json please.\\n')\n",
        "upload_file_to_colab()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Upload train.json please.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-609f4acc-0536-499b-a1a4-f7fc9088d847\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-609f4acc-0536-499b-a1a4-f7fc9088d847\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train.json to train.json\n",
            "User uploaded file \"train.json\" with length 8695710 bytes.\n",
            "Upload test.json please.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-24841033-3561-47e2-bda8-be9aa589dfff\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-24841033-3561-47e2-bda8-be9aa589dfff\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test.json to test.json\n",
            "User uploaded file \"test.json\" with length 4098518 bytes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1SwKA_S8Tq3"
      },
      "source": [
        "## 3. Data Pre-processing\n",
        "1. Create a funciton `sentence_regex()` for do `Regular Expression`. When putting a sentence in this function, return a sentence that finished regular expression\n",
        "2. Create `remove_empty_row()` function for remove all empty rows from dataframe.\n",
        "3. Create `label_to_spam()` function for label data. If the value of column(`is_spam`) is `True`, return 1 else 0. \n",
        "4. Create a function `preprocessing_data()`. That is the main function of our pre-processing step. In this function, it will call all the above to process all sentences.\n",
        "5. Call `preprocessing_data()` twice for both `test.json` and `train.json`.\n",
        "6. Create dictionary objects for easy conversion to dataframe and remove empty rows.\n",
        "7. Here, we just want to know the number of each label. (0 or 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uen19Q9uqGXQ"
      },
      "source": [
        "# Step 1.\n",
        "def sentence_regex(sentence):\n",
        "  complie = re.compile(u\"[\\u4e00-\\u9fa5]+\")\n",
        "\n",
        "  sentence = sentence.replace(\"\\n\", ' ')\n",
        "  sentence = re.sub(u'[a-zA-Z0-9]', '', sentence)\n",
        "\n",
        "  sentence = re.findall(complie, sentence) #一則評論只取中文字，分成多行\n",
        "  return ''.join(sentence)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skPZvvJU0G0G"
      },
      "source": [
        "# Step 2.\n",
        "def remove_empty_row(df, col='text'):\n",
        "  emptyTitleFIlter = (\n",
        "        (df[col].isnull())|(df[col] == '')|(df[col] == '0')\n",
        "        )\n",
        "  df = df[~emptyTitleFIlter]\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOI0PiAMyDhy"
      },
      "source": [
        "# Step 3.\n",
        "def label_to_spam(is_spam):\n",
        "  if is_spam == True:\n",
        "      return 1 \n",
        "  return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9fZU9dZuN26"
      },
      "source": [
        "# step 4.\n",
        "def preprocessing_data(filePath):\n",
        "    data = pd.read_json(filePath)\n",
        "\n",
        "    contents = list()\n",
        "    spamLabels = list()\n",
        "    length = len(data)\n",
        "\n",
        "    # iterate each row, sentence(content) and label(is_spam), by index.\n",
        "    for idx in range(length):\n",
        "      sentence = data['content'][idx]\n",
        "      is_spam = data['is_spam'][idx]\n",
        "\n",
        "      # do regular expression\n",
        "      # when finished, append it to a list (contents)\n",
        "      sentence = sentence_regex(sentence)\n",
        "      contents.append(sentence)\n",
        "      \n",
        "      # encode `is_spam` value.\n",
        "      # when finished, append it to a list (spamLabels)\n",
        "      is_spam = label_to_spam(is_spam)\n",
        "      spamLabels.append(is_spam)\n",
        "\n",
        "    return contents, spamLabels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHe34Si6u3t3",
        "outputId": "24bd89af-fe57-42c9-f5e0-b3dba11a630a"
      },
      "source": [
        "# Step 5.\n",
        "train_contents, train_spamLabels = preprocessing_data('train.json')\n",
        "print('* Train File:\\n\\tFirst sentence:', train_contents[0], '\\n\\tFirst label:', train_spamLabels[0])\n",
        "\n",
        "test_contents, test_spamLabels = preprocessing_data('test.json')\n",
        "print('* Test File:\\n\\tFirst sentence:', test_contents[0], '\\n\\tFirst label:', test_spamLabels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "* Train File:\n",
            "\tFirst sentence: 今天在亞太問到空機價是一萬九三月中上市要等嗎 \n",
            "\tFirst label: 1\n",
            "* Test File:\n",
            "\tFirst sentence: 前陣子才購入心愛的珊瑚粉用到現在覺得還滿上手的借給朋友玩他們都驚呼速度很快順暢無比不會這不經讓我小小得意一下呵呵笑為了讓好好發揮最大效能衝一下因此安裝了許多遊戲工具導航照相的不過問題就由此而生啦出門在外使用這些電力一下就不足了有時候又找不到可以充電的地方沒電真的是很無奈囧開始想要添購行動電源的念頭搜尋一下發現有好多種牌子有些價錢便宜到誇張不敢下手希望是看起來有質感且大容量的行動電源不知道大家有什麼好的推薦嗎 \n",
            "\tFirst label: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ijRz-8c1wHIg",
        "outputId": "18a11721-8a5e-4b5e-e3b6-f03695205a01"
      },
      "source": [
        "# Step 6 for train.json data\n",
        "trainDict = {\n",
        "    'text': train_contents,\n",
        "    'label': train_spamLabels\n",
        "}\n",
        "\n",
        "trainDf = DataFrame(trainDict)\n",
        "trainDf = remove_empty_row(trainDf, 'text')\n",
        "trainDf.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>今天在亞太問到空機價是一萬九三月中上市要等嗎</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>之前在亞太的上看到即將上市的訊息後之後就都是謠言了門市人員也不確定上市時間讓人一直懸在那期待...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>星期六的午後新竹南寮漁港旁雲水一方庭園餐廳銀河帶著他的筆記來拜訪薄薄的一本大大的面子亮亮的眼...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>昨天去中華門市玩了一下手機想說趁最近資訊展的時候入手一支應該可以便宜一點不過玩了半天好像都沒...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>體驗會時間年月日日開始入場首先感謝和舉辦這次的體驗會我很榮幸的能夠成為台中場的體驗者接下來我...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0                             今天在亞太問到空機價是一萬九三月中上市要等嗎      1\n",
              "1  之前在亞太的上看到即將上市的訊息後之後就都是謠言了門市人員也不確定上市時間讓人一直懸在那期待...      1\n",
              "2  星期六的午後新竹南寮漁港旁雲水一方庭園餐廳銀河帶著他的筆記來拜訪薄薄的一本大大的面子亮亮的眼...      1\n",
              "3  昨天去中華門市玩了一下手機想說趁最近資訊展的時候入手一支應該可以便宜一點不過玩了半天好像都沒...      1\n",
              "4  體驗會時間年月日日開始入場首先感謝和舉辦這次的體驗會我很榮幸的能夠成為台中場的體驗者接下來我...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Rds37YG295Mw",
        "outputId": "76b91a9e-c1fc-40a7-9311-5243b79e2dce"
      },
      "source": [
        "# Step 6 for test.json data\n",
        "testDict = {\n",
        "    'text': test_contents,\n",
        "    'label': test_spamLabels\n",
        "}\n",
        "\n",
        "testDf = DataFrame(testDict)\n",
        "testDf = remove_empty_row(testDf, 'text')\n",
        "testDf.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>前陣子才購入心愛的珊瑚粉用到現在覺得還滿上手的借給朋友玩他們都驚呼速度很快順暢無比不會這不經...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>慕名已久的機皇風評一直都是很不錯正猶豫是否下手的時候就聽說要推出新的顏色所以又再延遲了一段時...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>繼上次參加過新竹體驗會後這次是第二次參加三星的體驗會雖然地點在台北其實高鐵捷運還算方便還是不...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>看到大家在砲轟早鳥禮才發現原來這麼多人都那麼看重贈品我覺得廠商給你再多再好的贈品最後還是會反...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>有人跟我一樣在等的嗎來簽名報到一下吧順便看看這產品的人氣期待度微冷笑其實剛好明天休假</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  前陣子才購入心愛的珊瑚粉用到現在覺得還滿上手的借給朋友玩他們都驚呼速度很快順暢無比不會這不經...      1\n",
              "1  慕名已久的機皇風評一直都是很不錯正猶豫是否下手的時候就聽說要推出新的顏色所以又再延遲了一段時...      1\n",
              "2  繼上次參加過新竹體驗會後這次是第二次參加三星的體驗會雖然地點在台北其實高鐵捷運還算方便還是不...      1\n",
              "3  看到大家在砲轟早鳥禮才發現原來這麼多人都那麼看重贈品我覺得廠商給你再多再好的贈品最後還是會反...      1\n",
              "4         有人跟我一樣在等的嗎來簽名報到一下吧順便看看這產品的人氣期待度微冷笑其實剛好明天休假      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exABqaeg1xNF",
        "outputId": "ae55f355-1213-4dd0-9aad-6576c9dd1982"
      },
      "source": [
        "# Step 7.\n",
        "# define mask(filters)\n",
        "train_true_filter = trainDf['label'] == 0\n",
        "train_fake_filter = trainDf['label'] == 1\n",
        "test_true_filter = testDf['label'] == 0\n",
        "test_fake_filter = testDf['label'] == 1\n",
        "\n",
        "true_train_count = len(trainDf.loc[train_true_filter])\n",
        "true_test_count = len(testDf.loc[test_true_filter])\n",
        "print('True Comment Count:', true_train_count + true_test_count)\n",
        "\n",
        "fake_train_count = len(trainDf.loc[train_fake_filter])\n",
        "fake_test_count = len(testDf.loc[test_fake_filter])\n",
        "print('Fake Comment Count:', fake_train_count + fake_test_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Comment Count: 15959\n",
            "Fake Comment Count: 749\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgPQ12kwy9zO"
      },
      "source": [
        "So far, the pre-processing of the text has been done. Before we do embedding, we need to merge two dataframe `trainDf` and `testDf`.\n",
        "1. Create `concat_two_dataframe()` function.\n",
        "2. Concate `trainDf` and `testDf`.\n",
        "3. Because Fake's number less than real's, random sampling from True's data and then set the ratio is 3:1.\n",
        "4. Call `concat_two_dataframe()` function again, as `dataset`, and this time we merge the data sampled. (`sampling_true_data` and `fake_data`)\n",
        "5. Get all `text` and all `label` from dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua1aH-5j8d-L"
      },
      "source": [
        "# Step 1.\n",
        "def concat_two_dataframe(df_1, df_2):\n",
        "  concated = pd.concat([df_1, df_2], axis=0)\n",
        "  concated = shuffle(concated)\n",
        "  # reset index\n",
        "  concated = concated.reset_index(drop=True)\n",
        "  return concated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIV25muq_8RK",
        "outputId": "66b2966a-33ac-4682-bffe-20f3e6bc98fc"
      },
      "source": [
        "# Step 2.1 concated train dataframe and test dataframe\n",
        "concated_df = concat_two_dataframe(trainDf, testDf)\n",
        "\n",
        "# Real and Fake Mask (filter)\n",
        "fake_label_filter = concated_df['label'] == 1\n",
        "true_label_filter = concated_df['label'] == 0\n",
        "\n",
        "fake_data = concated_df.loc[fake_label_filter]\n",
        "true_data = concated_df.loc[true_label_filter]\n",
        "\n",
        "# Step 2.2 See the number of each label.\n",
        "print('Real data total number:', len(true_data))\n",
        "print('Fake data total number:', len(fake_data))\n",
        "\n",
        "# Step 3.\n",
        "# Because Fake's number less than real's.\n",
        "# random sampling from True's data.\n",
        "# set the ratio is 3:1\n",
        "sampling_true_data = true_data.sample(\n",
        "    n=len(fake_data) * 3,\n",
        "    random_state=5487\n",
        "  )\n",
        "\n",
        "# Step 4.\n",
        "dataset = concat_two_dataframe(sampling_true_data, fake_data)\n",
        "dataset.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Real data total number: 15959\n",
            "Fake data total number: 749\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2996 entries, 0 to 2995\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    2996 non-null   object\n",
            " 1   label   2996 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 46.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-p632loDn4t"
      },
      "source": [
        "# Step 5.\n",
        "texts = dataset['text'].values\n",
        "labels = dataset['label'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkNeYJfR2Fgr"
      },
      "source": [
        "## 4. BERT Embedding\n",
        "We can BERT embeddings now. In this tutorial, we load `bert-base-chinese`.\n",
        "1. Instance a `tokenizer` object for encode each sentence.\n",
        "2. Create `encode_sentence_by_bert()` for encoding every sentence place in this function.\n",
        "3. Define a list(`input_id`) for storing all encoded tokens from BERT's tokenizer.\n",
        "4. Pad sequences length to 100.\n",
        "5. Create `MASK` list.\n",
        "6. Convert data to tensor.\n",
        "7. Create the `DataLoader` object for our training set.\n",
        "8. Create BERT model and load BERT config.\n",
        "9. Check GUP avalible.\n",
        "10. Iterate batch data from our dataloader, and do embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaqlXRdeFEH2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "093d2397112f445a8d2b82b482f84135",
            "a2a6f2d4752d4a59a0bb197b9823ba5d",
            "f7ff4983dc5e49b3ba3d2a895bfff2d8",
            "c0c5c91b332c4a949984508f5a9f6846",
            "75dbd74d18df4a578376e41dcb0807f3",
            "719ce46fb09946d89e7d16d5c7a5b49b",
            "334f7b64c0aa496aabe86585be111b4b",
            "46bf5dd493b64caaa07cc2bb5719f376"
          ]
        },
        "outputId": "a653298d-d1ea-4253-a70f-86d1e8f114f4"
      },
      "source": [
        "# Step 1.\n",
        "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n",
        "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "093d2397112f445a8d2b82b482f84135",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=109540.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGEeHCdkHT1i"
      },
      "source": [
        "# Step 2.\n",
        "def encode_sentence_by_bert(sentence):\n",
        "  encoded_sentence = tokenizer.encode(\n",
        "        sentence, # Sentence to encode.\n",
        "        add_special_tokens = True, # add [CLS] and [SEP]\n",
        "        truncation = True,\n",
        "        max_length = 100 \n",
        "    )\n",
        "  return encoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGhxmRH6HgL0",
        "outputId": "effa5d58-bb59-4ad4-b690-6a59ff6b7612"
      },
      "source": [
        "# Step 3.\n",
        "input_ids = list()\n",
        "\n",
        "# encode each sentence in texts.\n",
        "for sentence in texts:\n",
        "  encoded_sentence = encode_sentence_by_bert(sentence)\n",
        "  # when sentence was encoded, append to input_ids list.\n",
        "  input_ids.append(encoded_sentence)\n",
        "\n",
        "print('Number of sentence:', len(input_ids))\n",
        "print('Length of encode sentence:', len(input_ids[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentence: 2996\n",
            "Length of encode sentence: 83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WghGw57GKFZg"
      },
      "source": [
        "# Step 4.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "MAX_LEN = 100\n",
        "input_ids = pad_sequences(\n",
        "    input_ids, \n",
        "    maxlen= MAX_LEN, \n",
        "    dtype=\"long\", \n",
        "    value=0, # padding by value 0\n",
        "    truncating=\"post\", # truncating from behind\n",
        "    padding=\"post\") # padding from behind"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGnfQ2yEMDXt"
      },
      "source": [
        "# Step 5.\n",
        "attention_masks = list()\n",
        "for sentence in input_ids:\n",
        "    att_mask = [int(token_id > 0) for token_id in sentence]\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kd6L_NPMUH8"
      },
      "source": [
        "# Step 6.\n",
        "inputs = torch.tensor(input_ids)\n",
        "labels = torch.tensor(labels)\n",
        "masks = torch.tensor(attention_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVjJdxzfMUvU"
      },
      "source": [
        "# Step 7. Create the DataLoader for our training set.\n",
        "batch_size = 8\n",
        "train_dataset = TensorDataset(inputs, masks, labels)\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c5bd7398144f4c438badd4107c5b31bd",
            "51189c61eb3f409e8c44a2999ca0a3d5",
            "a19a3777d22a47499f969140bbf5cc81",
            "1675a331a4bf4dcdb01b13b0eb16061d",
            "0d261218e0f145d6815d8f083f0ee85f",
            "8f1581dc14f74c3dac91a927be256d07",
            "6607cd0aba58499cad804710f14e73df",
            "8f23230f23f14135b5ec9bfc42d8b89f",
            "4c9dc13925324d6c92fe4e544de90aa2",
            "9d6db7be0b35438288bbeecef3273d72",
            "51ffb8ad2d9c4d4a858a6a91aa1a028d",
            "c7c4c47e20704faebf46a6e8f178de0d",
            "8a8807e6a92d4990879024c89281f5e8",
            "437f70eff79b4e0b8c8ee17c4d78d721",
            "70c9941a45524b118567dc114877c5e2",
            "104e911b4013474daae96dc54c476eb7"
          ]
        },
        "id": "sldXOldEMYom",
        "outputId": "56930574-19eb-41fe-8f0d-3b864710eeba"
      },
      "source": [
        "# Step 8. \n",
        "# Create BERT model\n",
        "'''\n",
        "The bare Bert Model transformer outputting raw hidden-states without any specific head on top.\n",
        "'''\n",
        "config = BertConfig.from_pretrained(PRETRAINED_MODEL_NAME, output_hidden_states=True)\n",
        "model = BertModel.from_pretrained(PRETRAINED_MODEL_NAME, config=config)\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5bd7398144f4c438badd4107c5b31bd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=624.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c9dc13925324d6c92fe4e544de90aa2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=411577189.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_K_RwmXdV67O",
        "outputId": "ee080d52-6683-4a7c-dbf3-bc9194c4affc"
      },
      "source": [
        "# Step 9. \n",
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8GtSx2XMcCn"
      },
      "source": [
        "# Step 10.\n",
        "train_label = list()\n",
        "train_set = list()\n",
        "\n",
        "count=0\n",
        "for step, batch in enumerate(train_dataloader):\n",
        "  batch_tensor = tuple(tensr.to(device) for tensr in batch)\n",
        "  # b_ means batch\n",
        "  b_input_ids, b_input_mask, b_labels = batch_tensor\n",
        "  outputs = model(b_input_ids, b_input_mask)\n",
        "\n",
        "  # get last_layer \n",
        "  last_layer = outputs[0] # last layer\n",
        "  label_ids = b_labels.to('cpu').numpy() \n",
        "  train_label.append(np.array(label_ids)) # real label for training a SVM model.\n",
        "\n",
        "  for state in last_layer:\n",
        "    # state size: (100, 768)\n",
        "    allWordVecs = list()\n",
        "    for word_unit in state:\n",
        "      # size (768)\n",
        "      allWordVecs.append(word_unit.detach().cpu().numpy())\n",
        "    train_set.append(allWordVecs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9BPzdRkV2zf",
        "outputId": "c6ea05f6-66a7-490c-a830-0928637db4d3"
      },
      "source": [
        "labels = list()\n",
        "for i in train_label:\n",
        "    for j in i:\n",
        "        labels.append(j)\n",
        "labels = np.array(labels)\n",
        "print('Length of Labels:', len(labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Labels: 2996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk8e1kE0e3sd",
        "outputId": "1587ac83-295a-43aa-c016-d88d40f7e54b"
      },
      "source": [
        "# Show the shape of train_set.\n",
        "layer = np.array(train_set)\n",
        "train_set = None\n",
        "print(layer.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2996, 100, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1nUMW3p75eZ"
      },
      "source": [
        "## 5. Build SVM Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CHBIDM7YRTN",
        "outputId": "e1bdb31d-6349-4319-e035-77014b849c4c"
      },
      "source": [
        "# split dataset \n",
        "X_train, X_test, y_train, y_test = \\\n",
        "    train_test_split(\n",
        "        layer, \n",
        "        labels,\n",
        "        test_size=0.3,\n",
        "        random_state=0,\n",
        "        stratify=labels\n",
        "    )\n",
        "\n",
        "# first feature CLS\n",
        "X_train = X_train[:, 0, :]\n",
        "X_test = X_test[:, 0, :]\n",
        "print(X_train.shape)\n",
        "\n",
        "model_svm = SVC(kernel='rbf')\n",
        "model_svm.fit(X_train, y_train)\n",
        "prediction = model_svm.predict(X_test)\n",
        "accuracy = metrics.accuracy_score(y_test, prediction.round())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2097, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47dOqiJNeXFm",
        "outputId": "a84eab07-5d30-4a00-b9ab-bca7caa2b25c"
      },
      "source": [
        "accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8832035595105673"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    }
  ]
}
