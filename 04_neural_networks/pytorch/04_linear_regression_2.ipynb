{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_n = 100\n",
    "input_feature = 3\n",
    "output_feature = 1\n",
    "epoch_n = 100\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "x = torch.rand(batch_n, input_feature) # row: 100, col: 3\n",
    "c = torch.Tensor([[3.],[5.],[1.]])\n",
    "# output label\n",
    "y = x.mm(c)\n",
    "y = y.add(torch.rand(batch_n, output_feature)) # not required "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(x[:, 0], y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7186],\n",
       "        [0.1061],\n",
       "        [0.3317]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight\n",
    "w = torch.rand(input_feature, output_feature)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 , loss: 21.5239\n",
      "epoch:1 , loss: 9.0549\n",
      "epoch:2 , loss: 3.9199\n",
      "epoch:3 , loss: 1.7859\n",
      "epoch:4 , loss: 0.8854\n",
      "epoch:5 , loss: 0.4955\n",
      "epoch:6 , loss: 0.3199\n",
      "epoch:7 , loss: 0.2360\n",
      "epoch:8 , loss: 0.1929\n",
      "epoch:9 , loss: 0.1687\n",
      "epoch:10 , loss: 0.1541\n",
      "epoch:11 , loss: 0.1445\n",
      "epoch:12 , loss: 0.1381\n",
      "epoch:13 , loss: 0.1335\n",
      "epoch:14 , loss: 0.1302\n",
      "epoch:15 , loss: 0.1279\n",
      "epoch:16 , loss: 0.1261\n",
      "epoch:17 , loss: 0.1249\n",
      "epoch:18 , loss: 0.1239\n",
      "epoch:19 , loss: 0.1232\n",
      "epoch:20 , loss: 0.1227\n",
      "epoch:21 , loss: 0.1223\n",
      "epoch:22 , loss: 0.1220\n",
      "epoch:23 , loss: 0.1218\n",
      "epoch:24 , loss: 0.1217\n",
      "epoch:25 , loss: 0.1216\n",
      "epoch:26 , loss: 0.1215\n",
      "epoch:27 , loss: 0.1214\n",
      "epoch:28 , loss: 0.1214\n",
      "epoch:29 , loss: 0.1213\n",
      "epoch:30 , loss: 0.1213\n",
      "epoch:31 , loss: 0.1213\n",
      "epoch:32 , loss: 0.1213\n",
      "epoch:33 , loss: 0.1212\n",
      "epoch:34 , loss: 0.1212\n",
      "epoch:35 , loss: 0.1212\n",
      "epoch:36 , loss: 0.1212\n",
      "epoch:37 , loss: 0.1212\n",
      "epoch:38 , loss: 0.1212\n",
      "epoch:39 , loss: 0.1212\n",
      "epoch:40 , loss: 0.1212\n",
      "epoch:41 , loss: 0.1212\n",
      "epoch:42 , loss: 0.1212\n",
      "epoch:43 , loss: 0.1212\n",
      "epoch:44 , loss: 0.1212\n",
      "epoch:45 , loss: 0.1212\n",
      "epoch:46 , loss: 0.1212\n",
      "epoch:47 , loss: 0.1212\n",
      "epoch:48 , loss: 0.1212\n",
      "epoch:49 , loss: 0.1212\n",
      "epoch:50 , loss: 0.1212\n",
      "epoch:51 , loss: 0.1212\n",
      "epoch:52 , loss: 0.1212\n",
      "epoch:53 , loss: 0.1212\n",
      "epoch:54 , loss: 0.1212\n",
      "epoch:55 , loss: 0.1212\n",
      "epoch:56 , loss: 0.1212\n",
      "epoch:57 , loss: 0.1212\n",
      "epoch:58 , loss: 0.1212\n",
      "epoch:59 , loss: 0.1212\n",
      "epoch:60 , loss: 0.1212\n",
      "epoch:61 , loss: 0.1212\n",
      "epoch:62 , loss: 0.1212\n",
      "epoch:63 , loss: 0.1212\n",
      "epoch:64 , loss: 0.1212\n",
      "epoch:65 , loss: 0.1212\n",
      "epoch:66 , loss: 0.1212\n",
      "epoch:67 , loss: 0.1212\n",
      "epoch:68 , loss: 0.1212\n",
      "epoch:69 , loss: 0.1212\n",
      "epoch:70 , loss: 0.1212\n",
      "epoch:71 , loss: 0.1212\n",
      "epoch:72 , loss: 0.1212\n",
      "epoch:73 , loss: 0.1212\n",
      "epoch:74 , loss: 0.1212\n",
      "epoch:75 , loss: 0.1212\n",
      "epoch:76 , loss: 0.1212\n",
      "epoch:77 , loss: 0.1212\n",
      "epoch:78 , loss: 0.1212\n",
      "epoch:79 , loss: 0.1212\n",
      "epoch:80 , loss: 0.1212\n",
      "epoch:81 , loss: 0.1212\n",
      "epoch:82 , loss: 0.1212\n",
      "epoch:83 , loss: 0.1212\n",
      "epoch:84 , loss: 0.1212\n",
      "epoch:85 , loss: 0.1212\n",
      "epoch:86 , loss: 0.1212\n",
      "epoch:87 , loss: 0.1212\n",
      "epoch:88 , loss: 0.1212\n",
      "epoch:89 , loss: 0.1212\n",
      "epoch:90 , loss: 0.1212\n",
      "epoch:91 , loss: 0.1212\n",
      "epoch:92 , loss: 0.1212\n",
      "epoch:93 , loss: 0.1212\n",
      "epoch:94 , loss: 0.1212\n",
      "epoch:95 , loss: 0.1212\n",
      "epoch:96 , loss: 0.1212\n",
      "epoch:97 , loss: 0.1212\n",
      "epoch:98 , loss: 0.1212\n",
      "epoch:99 , loss: 0.1212\n"
     ]
    }
   ],
   "source": [
    "# 土法煉鋼\n",
    "for epoch in range(epoch_n):\n",
    "    y_predict = x.mm(w)\n",
    "    # define loss function\n",
    "    loss = (y_predict - y).pow(2).mean()\n",
    "    print('epoch:{} , loss: {:.4f}'.format(epoch, loss))\n",
    "    \n",
    "    # gredient \n",
    "    grad_y_pridict = 2 * ( y_predict - y )\n",
    "    grad_w = x.t().mm(grad_y_pridict) # w gradient\n",
    "    \n",
    "    # update weight\n",
    "    w -= grad_w * learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.3129],\n",
       "        [5.3394],\n",
       "        [1.2536]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w # weight close to c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 , loss: 22.2578\n",
      "epoch:1 , loss: 21.5607\n",
      "epoch:2 , loss: 20.8861\n",
      "epoch:3 , loss: 20.2333\n",
      "epoch:4 , loss: 19.6017\n",
      "epoch:5 , loss: 18.9906\n",
      "epoch:6 , loss: 18.3992\n",
      "epoch:7 , loss: 17.8270\n",
      "epoch:8 , loss: 17.2733\n",
      "epoch:9 , loss: 16.7375\n",
      "epoch:10 , loss: 16.2191\n",
      "epoch:11 , loss: 15.7174\n",
      "epoch:12 , loss: 15.2320\n",
      "epoch:13 , loss: 14.7623\n",
      "epoch:14 , loss: 14.3077\n",
      "epoch:15 , loss: 13.8679\n",
      "epoch:16 , loss: 13.4423\n",
      "epoch:17 , loss: 13.0304\n",
      "epoch:18 , loss: 12.6319\n",
      "epoch:19 , loss: 12.2462\n",
      "epoch:20 , loss: 11.8730\n",
      "epoch:21 , loss: 11.5119\n",
      "epoch:22 , loss: 11.1624\n",
      "epoch:23 , loss: 10.8243\n",
      "epoch:24 , loss: 10.4970\n",
      "epoch:25 , loss: 10.1803\n",
      "epoch:26 , loss: 9.8739\n",
      "epoch:27 , loss: 9.5773\n",
      "epoch:28 , loss: 9.2903\n",
      "epoch:29 , loss: 9.0125\n",
      "epoch:30 , loss: 8.7438\n",
      "epoch:31 , loss: 8.4836\n",
      "epoch:32 , loss: 8.2319\n",
      "epoch:33 , loss: 7.9883\n",
      "epoch:34 , loss: 7.7526\n",
      "epoch:35 , loss: 7.5244\n",
      "epoch:36 , loss: 7.3036\n",
      "epoch:37 , loss: 7.0899\n",
      "epoch:38 , loss: 6.8831\n",
      "epoch:39 , loss: 6.6829\n",
      "epoch:40 , loss: 6.4892\n",
      "epoch:41 , loss: 6.3017\n",
      "epoch:42 , loss: 6.1202\n",
      "epoch:43 , loss: 5.9446\n",
      "epoch:44 , loss: 5.7746\n",
      "epoch:45 , loss: 5.6101\n",
      "epoch:46 , loss: 5.4509\n",
      "epoch:47 , loss: 5.2968\n",
      "epoch:48 , loss: 5.1476\n",
      "epoch:49 , loss: 5.0032\n",
      "epoch:50 , loss: 4.8634\n",
      "epoch:51 , loss: 4.7282\n",
      "epoch:52 , loss: 4.5972\n",
      "epoch:53 , loss: 4.4705\n",
      "epoch:54 , loss: 4.3478\n",
      "epoch:55 , loss: 4.2290\n",
      "epoch:56 , loss: 4.1141\n",
      "epoch:57 , loss: 4.0028\n",
      "epoch:58 , loss: 3.8951\n",
      "epoch:59 , loss: 3.7908\n",
      "epoch:60 , loss: 3.6898\n",
      "epoch:61 , loss: 3.5921\n",
      "epoch:62 , loss: 3.4975\n",
      "epoch:63 , loss: 3.4059\n",
      "epoch:64 , loss: 3.3172\n",
      "epoch:65 , loss: 3.2314\n",
      "epoch:66 , loss: 3.1483\n",
      "epoch:67 , loss: 3.0678\n",
      "epoch:68 , loss: 2.9899\n",
      "epoch:69 , loss: 2.9144\n",
      "epoch:70 , loss: 2.8414\n",
      "epoch:71 , loss: 2.7706\n",
      "epoch:72 , loss: 2.7021\n",
      "epoch:73 , loss: 2.6358\n",
      "epoch:74 , loss: 2.5716\n",
      "epoch:75 , loss: 2.5094\n",
      "epoch:76 , loss: 2.4492\n",
      "epoch:77 , loss: 2.3909\n",
      "epoch:78 , loss: 2.3344\n",
      "epoch:79 , loss: 2.2797\n",
      "epoch:80 , loss: 2.2267\n",
      "epoch:81 , loss: 2.1754\n",
      "epoch:82 , loss: 2.1257\n",
      "epoch:83 , loss: 2.0776\n",
      "epoch:84 , loss: 2.0309\n",
      "epoch:85 , loss: 1.9858\n",
      "epoch:86 , loss: 1.9420\n",
      "epoch:87 , loss: 1.8996\n",
      "epoch:88 , loss: 1.8586\n",
      "epoch:89 , loss: 1.8188\n",
      "epoch:90 , loss: 1.7803\n",
      "epoch:91 , loss: 1.7429\n",
      "epoch:92 , loss: 1.7068\n",
      "epoch:93 , loss: 1.6717\n",
      "epoch:94 , loss: 1.6377\n",
      "epoch:95 , loss: 1.6048\n",
      "epoch:96 , loss: 1.5729\n",
      "epoch:97 , loss: 1.5420\n",
      "epoch:98 , loss: 1.5121\n",
      "epoch:99 , loss: 1.4830\n"
     ]
    }
   ],
   "source": [
    "w = torch.rand(input_feature, output_feature)\n",
    "\n",
    "Vx = Variable(x, requires_grad = False)\n",
    "Vy = Variable(y, requires_grad = False)\n",
    "Vw = Variable(w, requires_grad = True)\n",
    "\n",
    "for epoch in range(epoch_n):\n",
    "    y_predict = Vx.mm(Vw)\n",
    "    # define loss function\n",
    "    loss = (y_predict - y).pow(2).mean()\n",
    "    \n",
    "    # backward\n",
    "    loss.backward() \n",
    "    print('epoch:{} , loss: {:.4f}'.format(epoch, loss))\n",
    "\n",
    "    Vw.data -= learning_rate * Vw.grad.data\n",
    "    Vw.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6359],\n",
       "        [2.9309],\n",
       "        [2.5877]], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01 nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Regression(nn.Module):\n",
    "    ''' super nn module '''\n",
    "    def __init__(self):\n",
    "        super(Regression, self).__init__()\n",
    "\n",
    "    def forward(self, x, w):\n",
    "        y_predict = x.mm(w)\n",
    "        return y_predict\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regression()\n",
    "w = torch.rand(input_feature, output_feature)\n",
    "Vw = Variable(w, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 , loss: 18.2551\n",
      "epoch:1 , loss: 17.6896\n",
      "epoch:2 , loss: 17.1424\n",
      "epoch:3 , loss: 16.6129\n",
      "epoch:4 , loss: 16.1005\n",
      "epoch:5 , loss: 15.6047\n",
      "epoch:6 , loss: 15.1249\n",
      "epoch:7 , loss: 14.6606\n",
      "epoch:8 , loss: 14.2114\n",
      "epoch:9 , loss: 13.7767\n",
      "epoch:10 , loss: 13.3560\n",
      "epoch:11 , loss: 12.9489\n",
      "epoch:12 , loss: 12.5550\n",
      "epoch:13 , loss: 12.1738\n",
      "epoch:14 , loss: 11.8049\n",
      "epoch:15 , loss: 11.4479\n",
      "epoch:16 , loss: 11.1025\n",
      "epoch:17 , loss: 10.7682\n",
      "epoch:18 , loss: 10.4446\n",
      "epoch:19 , loss: 10.1316\n",
      "epoch:20 , loss: 9.8286\n",
      "epoch:21 , loss: 9.5354\n",
      "epoch:22 , loss: 9.2517\n",
      "epoch:23 , loss: 8.9771\n",
      "epoch:24 , loss: 8.7113\n",
      "epoch:25 , loss: 8.4542\n",
      "epoch:26 , loss: 8.2053\n",
      "epoch:27 , loss: 7.9644\n",
      "epoch:28 , loss: 7.7313\n",
      "epoch:29 , loss: 7.5057\n",
      "epoch:30 , loss: 7.2873\n",
      "epoch:31 , loss: 7.0760\n",
      "epoch:32 , loss: 6.8715\n",
      "epoch:33 , loss: 6.6735\n",
      "epoch:34 , loss: 6.4819\n",
      "epoch:35 , loss: 6.2965\n",
      "epoch:36 , loss: 6.1170\n",
      "epoch:37 , loss: 5.9433\n",
      "epoch:38 , loss: 5.7752\n",
      "epoch:39 , loss: 5.6125\n",
      "epoch:40 , loss: 5.4550\n",
      "epoch:41 , loss: 5.3025\n",
      "epoch:42 , loss: 5.1549\n",
      "epoch:43 , loss: 5.0121\n",
      "epoch:44 , loss: 4.8738\n",
      "epoch:45 , loss: 4.7400\n",
      "epoch:46 , loss: 4.6104\n",
      "epoch:47 , loss: 4.4850\n",
      "epoch:48 , loss: 4.3636\n",
      "epoch:49 , loss: 4.2461\n",
      "epoch:50 , loss: 4.1323\n",
      "epoch:51 , loss: 4.0222\n",
      "epoch:52 , loss: 3.9155\n",
      "epoch:53 , loss: 3.8123\n",
      "epoch:54 , loss: 3.7124\n",
      "epoch:55 , loss: 3.6156\n",
      "epoch:56 , loss: 3.5220\n",
      "epoch:57 , loss: 3.4313\n",
      "epoch:58 , loss: 3.3435\n",
      "epoch:59 , loss: 3.2585\n",
      "epoch:60 , loss: 3.1762\n",
      "epoch:61 , loss: 3.0965\n",
      "epoch:62 , loss: 3.0193\n",
      "epoch:63 , loss: 2.9446\n",
      "epoch:64 , loss: 2.8722\n",
      "epoch:65 , loss: 2.8021\n",
      "epoch:66 , loss: 2.7343\n",
      "epoch:67 , loss: 2.6686\n",
      "epoch:68 , loss: 2.6049\n",
      "epoch:69 , loss: 2.5433\n",
      "epoch:70 , loss: 2.4836\n",
      "epoch:71 , loss: 2.4258\n",
      "epoch:72 , loss: 2.3698\n",
      "epoch:73 , loss: 2.3156\n",
      "epoch:74 , loss: 2.2631\n",
      "epoch:75 , loss: 2.2122\n",
      "epoch:76 , loss: 2.1629\n",
      "epoch:77 , loss: 2.1152\n",
      "epoch:78 , loss: 2.0689\n",
      "epoch:79 , loss: 2.0241\n",
      "epoch:80 , loss: 1.9807\n",
      "epoch:81 , loss: 1.9386\n",
      "epoch:82 , loss: 1.8979\n",
      "epoch:83 , loss: 1.8584\n",
      "epoch:84 , loss: 1.8201\n",
      "epoch:85 , loss: 1.7831\n",
      "epoch:86 , loss: 1.7472\n",
      "epoch:87 , loss: 1.7123\n",
      "epoch:88 , loss: 1.6786\n",
      "epoch:89 , loss: 1.6459\n",
      "epoch:90 , loss: 1.6142\n",
      "epoch:91 , loss: 1.5835\n",
      "epoch:92 , loss: 1.5537\n",
      "epoch:93 , loss: 1.5249\n",
      "epoch:94 , loss: 1.4969\n",
      "epoch:95 , loss: 1.4697\n",
      "epoch:96 , loss: 1.4434\n",
      "epoch:97 , loss: 1.4179\n",
      "epoch:98 , loss: 1.3932\n",
      "epoch:99 , loss: 1.3692\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_n):\n",
    "    # nn model\n",
    "    y_predict = model(Vx, Vw)\n",
    "    \n",
    "    # define loss function\n",
    "    loss = (y_predict - y).pow(2).mean()\n",
    "    # backward\n",
    "    loss.backward() \n",
    "    \n",
    "    print('epoch:{} , loss: {:.4f}'.format(epoch, loss))\n",
    "\n",
    "    Vw.data -= learning_rate * Vw.grad.data\n",
    "    Vw.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 Replace forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression(nn.Module):\n",
    "    ''' nn.Linear repplace x.mm(x) '''\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(Regression, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_predict = self.linear(x)\n",
    "        return y_predict\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression(\n",
      "  (linear): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Regression(input_feature, output_feature)\n",
    "loss_fn = nn.MSELoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 , loss: 27.7585\n",
      "epoch:1 , loss: 25.9103\n",
      "epoch:2 , loss: 24.1909\n",
      "epoch:3 , loss: 22.5911\n",
      "epoch:4 , loss: 21.1027\n",
      "epoch:5 , loss: 19.7178\n",
      "epoch:6 , loss: 18.4293\n",
      "epoch:7 , loss: 17.2304\n",
      "epoch:8 , loss: 16.1149\n",
      "epoch:9 , loss: 15.0769\n",
      "epoch:10 , loss: 14.1112\n",
      "epoch:11 , loss: 13.2125\n",
      "epoch:12 , loss: 12.3763\n",
      "epoch:13 , loss: 11.5982\n",
      "epoch:14 , loss: 10.8741\n",
      "epoch:15 , loss: 10.2003\n",
      "epoch:16 , loss: 9.5733\n",
      "epoch:17 , loss: 8.9898\n",
      "epoch:18 , loss: 8.4467\n",
      "epoch:19 , loss: 7.9413\n",
      "epoch:20 , loss: 7.4710\n",
      "epoch:21 , loss: 7.0332\n",
      "epoch:22 , loss: 6.6257\n",
      "epoch:23 , loss: 6.2465\n",
      "epoch:24 , loss: 5.8934\n",
      "epoch:25 , loss: 5.5648\n",
      "epoch:26 , loss: 5.2589\n",
      "epoch:27 , loss: 4.9741\n",
      "epoch:28 , loss: 4.7089\n",
      "epoch:29 , loss: 4.4620\n",
      "epoch:30 , loss: 4.2322\n",
      "epoch:31 , loss: 4.0181\n",
      "epoch:32 , loss: 3.8188\n",
      "epoch:33 , loss: 3.6331\n",
      "epoch:34 , loss: 3.4602\n",
      "epoch:35 , loss: 3.2992\n",
      "epoch:36 , loss: 3.1492\n",
      "epoch:37 , loss: 3.0094\n",
      "epoch:38 , loss: 2.8792\n",
      "epoch:39 , loss: 2.7578\n",
      "epoch:40 , loss: 2.6447\n",
      "epoch:41 , loss: 2.5393\n",
      "epoch:42 , loss: 2.4410\n",
      "epoch:43 , loss: 2.3494\n",
      "epoch:44 , loss: 2.2640\n",
      "epoch:45 , loss: 2.1843\n",
      "epoch:46 , loss: 2.1100\n",
      "epoch:47 , loss: 2.0406\n",
      "epoch:48 , loss: 1.9759\n",
      "epoch:49 , loss: 1.9155\n",
      "epoch:50 , loss: 1.8592\n",
      "epoch:51 , loss: 1.8065\n",
      "epoch:52 , loss: 1.7573\n",
      "epoch:53 , loss: 1.7114\n",
      "epoch:54 , loss: 1.6685\n",
      "epoch:55 , loss: 1.6283\n",
      "epoch:56 , loss: 1.5908\n",
      "epoch:57 , loss: 1.5557\n",
      "epoch:58 , loss: 1.5228\n",
      "epoch:59 , loss: 1.4921\n",
      "epoch:60 , loss: 1.4633\n",
      "epoch:61 , loss: 1.4363\n",
      "epoch:62 , loss: 1.4110\n",
      "epoch:63 , loss: 1.3873\n",
      "epoch:64 , loss: 1.3650\n",
      "epoch:65 , loss: 1.3441\n",
      "epoch:66 , loss: 1.3245\n",
      "epoch:67 , loss: 1.3060\n",
      "epoch:68 , loss: 1.2887\n",
      "epoch:69 , loss: 1.2723\n",
      "epoch:70 , loss: 1.2570\n",
      "epoch:71 , loss: 1.2425\n",
      "epoch:72 , loss: 1.2288\n",
      "epoch:73 , loss: 1.2159\n",
      "epoch:74 , loss: 1.2037\n",
      "epoch:75 , loss: 1.1922\n",
      "epoch:76 , loss: 1.1813\n",
      "epoch:77 , loss: 1.1710\n",
      "epoch:78 , loss: 1.1612\n",
      "epoch:79 , loss: 1.1519\n",
      "epoch:80 , loss: 1.1431\n",
      "epoch:81 , loss: 1.1347\n",
      "epoch:82 , loss: 1.1267\n",
      "epoch:83 , loss: 1.1191\n",
      "epoch:84 , loss: 1.1118\n",
      "epoch:85 , loss: 1.1049\n",
      "epoch:86 , loss: 1.0983\n",
      "epoch:87 , loss: 1.0919\n",
      "epoch:88 , loss: 1.0859\n",
      "epoch:89 , loss: 1.0800\n",
      "epoch:90 , loss: 1.0744\n",
      "epoch:91 , loss: 1.0691\n",
      "epoch:92 , loss: 1.0639\n",
      "epoch:93 , loss: 1.0589\n",
      "epoch:94 , loss: 1.0541\n",
      "epoch:95 , loss: 1.0494\n",
      "epoch:96 , loss: 1.0449\n",
      "epoch:97 , loss: 1.0405\n",
      "epoch:98 , loss: 1.0363\n",
      "epoch:99 , loss: 1.0322\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_n):\n",
    "    \n",
    "    y_predict = model(Vx)\n",
    "    \n",
    "    # nn.MSELoss()\n",
    "    loss = loss_fn(y_predict, y)\n",
    "    \n",
    "    model.zero_grad() \n",
    "\n",
    "    loss.backward() \n",
    "    print('epoch:{} , loss: {:.4f}'.format(epoch, loss))\n",
    "    \n",
    "    for param in model.parameters(): # list\n",
    "        # get w from Variables\n",
    "        param.data -= learning_rate * param.grad.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03 Replace OPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as opt\n",
    "model = Regression(input_feature, output_feature)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = opt.SGD(model.parameters(), lr=learning_rate) # 要 update model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 , loss: 27.8291\n",
      "epoch:1 , loss: 25.9909\n",
      "epoch:2 , loss: 24.2807\n",
      "epoch:3 , loss: 22.6895\n",
      "epoch:4 , loss: 21.2091\n",
      "epoch:5 , loss: 19.8316\n",
      "epoch:6 , loss: 18.5499\n",
      "epoch:7 , loss: 17.3574\n",
      "epoch:8 , loss: 16.2477\n",
      "epoch:9 , loss: 15.2153\n",
      "epoch:10 , loss: 14.2545\n",
      "epoch:11 , loss: 13.3605\n",
      "epoch:12 , loss: 12.5286\n",
      "epoch:13 , loss: 11.7545\n",
      "epoch:14 , loss: 11.0341\n",
      "epoch:15 , loss: 10.3638\n",
      "epoch:16 , loss: 9.7399\n",
      "epoch:17 , loss: 9.1593\n",
      "epoch:18 , loss: 8.6189\n",
      "epoch:19 , loss: 8.1160\n",
      "epoch:20 , loss: 7.6479\n",
      "epoch:21 , loss: 7.2122\n",
      "epoch:22 , loss: 6.8067\n",
      "epoch:23 , loss: 6.4291\n",
      "epoch:24 , loss: 6.0777\n",
      "epoch:25 , loss: 5.7506\n",
      "epoch:26 , loss: 5.4460\n",
      "epoch:27 , loss: 5.1625\n",
      "epoch:28 , loss: 4.8984\n",
      "epoch:29 , loss: 4.6526\n",
      "epoch:30 , loss: 4.4236\n",
      "epoch:31 , loss: 4.2104\n",
      "epoch:32 , loss: 4.0119\n",
      "epoch:33 , loss: 3.8269\n",
      "epoch:34 , loss: 3.6546\n",
      "epoch:35 , loss: 3.4941\n",
      "epoch:36 , loss: 3.3446\n",
      "epoch:37 , loss: 3.2052\n",
      "epoch:38 , loss: 3.0754\n",
      "epoch:39 , loss: 2.9543\n",
      "epoch:40 , loss: 2.8415\n",
      "epoch:41 , loss: 2.7363\n",
      "epoch:42 , loss: 2.6383\n",
      "epoch:43 , loss: 2.5468\n",
      "epoch:44 , loss: 2.4615\n",
      "epoch:45 , loss: 2.3819\n",
      "epoch:46 , loss: 2.3077\n",
      "epoch:47 , loss: 2.2384\n",
      "epoch:48 , loss: 2.1737\n",
      "epoch:49 , loss: 2.1133\n",
      "epoch:50 , loss: 2.0569\n",
      "epoch:51 , loss: 2.0042\n",
      "epoch:52 , loss: 1.9549\n",
      "epoch:53 , loss: 1.9089\n",
      "epoch:54 , loss: 1.8659\n",
      "epoch:55 , loss: 1.8256\n",
      "epoch:56 , loss: 1.7879\n",
      "epoch:57 , loss: 1.7527\n",
      "epoch:58 , loss: 1.7197\n",
      "epoch:59 , loss: 1.6887\n",
      "epoch:60 , loss: 1.6597\n",
      "epoch:61 , loss: 1.6326\n",
      "epoch:62 , loss: 1.6071\n",
      "epoch:63 , loss: 1.5831\n",
      "epoch:64 , loss: 1.5606\n",
      "epoch:65 , loss: 1.5395\n",
      "epoch:66 , loss: 1.5196\n",
      "epoch:67 , loss: 1.5010\n",
      "epoch:68 , loss: 1.4834\n",
      "epoch:69 , loss: 1.4668\n",
      "epoch:70 , loss: 1.4511\n",
      "epoch:71 , loss: 1.4364\n",
      "epoch:72 , loss: 1.4225\n",
      "epoch:73 , loss: 1.4093\n",
      "epoch:74 , loss: 1.3968\n",
      "epoch:75 , loss: 1.3850\n",
      "epoch:76 , loss: 1.3739\n",
      "epoch:77 , loss: 1.3632\n",
      "epoch:78 , loss: 1.3532\n",
      "epoch:79 , loss: 1.3436\n",
      "epoch:80 , loss: 1.3345\n",
      "epoch:81 , loss: 1.3258\n",
      "epoch:82 , loss: 1.3175\n",
      "epoch:83 , loss: 1.3096\n",
      "epoch:84 , loss: 1.3021\n",
      "epoch:85 , loss: 1.2949\n",
      "epoch:86 , loss: 1.2879\n",
      "epoch:87 , loss: 1.2813\n",
      "epoch:88 , loss: 1.2749\n",
      "epoch:89 , loss: 1.2688\n",
      "epoch:90 , loss: 1.2629\n",
      "epoch:91 , loss: 1.2572\n",
      "epoch:92 , loss: 1.2517\n",
      "epoch:93 , loss: 1.2464\n",
      "epoch:94 , loss: 1.2413\n",
      "epoch:95 , loss: 1.2363\n",
      "epoch:96 , loss: 1.2315\n",
      "epoch:97 , loss: 1.2268\n",
      "epoch:98 , loss: 1.2223\n",
      "epoch:99 , loss: 1.2179\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_n):\n",
    "    y_predict = model(Vx)\n",
    "    loss = loss_fn(y_predict, y)\n",
    "\n",
    "    model.zero_grad() \n",
    "\n",
    "    loss.backward() \n",
    "    print('epoch:{} , loss: {:.4f}'.format(epoch, loss))\n",
    "\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
